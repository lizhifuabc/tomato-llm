### 设置要处理的文件资源路径
### 例如: app.resource=file:///Users/yourname/Downloads/yourfile.pdf
###    或者 app.resource=classpath:/data/myfile.pdf
app:
  resource: https://www.baidu.com/  # 示例URL资源路径
spring:
  ai:
    ollama:
      embedding:
        options:
          model: mistral:latest  # # 配置 Ollama AI 使用的嵌入模型版本为 llama3.1:latest
      chat:
        options:
          model: qwen2:latest  # 设置 Ollama 模型名称
      base-url: ${AI_OLLAMA_BASE_URL:http://192.168.18.64:11434}  # Ollama API 基本 URL
    vectorstore:
      chroma:
        initialize-schema: true  # 是否初始化 Chroma 向量数据库的架构
        client:
          host: ${CHROMA_HOST:http://192.168.18.64}  # 需要替换为自己的 Chroma 服务地址
          port: ${CHROMA_PORT:8000}  # 需要替换为自己的 Chroma 服务端口
    chat:
      observations:
        include-prompt: true  # 是否包含对话提示
        include-completion: true  # 是否包含对话完成
  application:
    name: tomato-llm-examples-rag  # 应用名称

management:
  endpoints:
    web:
      exposure:
        include:
          - health  # 暴露健康检查端点
          - metrics  # 暴露应用度量端点
          - prometheus  # 暴露 Prometheus 度量端点

  ### 设置采样概率为 1.0，启用 100% 请求的追踪
  tracing:
    sampling:
      probability: 1.0  # 采样率，设置为 1.0 表示全部请求都进行追踪
  zipkin:
    tracing:
      endpoint: ${ZIPKIN_BASE_URL:http://192.168.18.64:9411}  # Zipkin API 基本 URL
